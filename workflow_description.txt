1. Preparing all tables
    - creating product_urls, product_data, product_images tables
2. Scraping and parsing
    - pulling all ready product urls from notion
    - write only which is not in db
    - take all not scraped urls
    - scrape and parse at once them all in browser session
    - if capcha appears break the session and continue with new session
    - write product data to product_data table
    - write img urls to product_images table
    - update scraped_status on product_urls table
3. Downloading images
    - take all images for one product to a list
    - dowload all images to images/ folder if error (bot detection) occurs retry ...
    - update download_status on product_images table
4. Text extraction
    - extract text from each image
    - write text to db
    - update text_extracted_status on product_images table
5. Text translation
    - take all not translated texts by status
    - translate them using open ai api
    - write translations to product_images table
6. Push to notion
    - gather all data into one json file for each product
    - push the file to google drive
    - update notion db with file_url on google drive
    - 